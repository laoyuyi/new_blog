#转录组
```shell
表达数据挖掘三张表：样本信息表（通过项目设计得到）、基因信息表（通过下载、注释得到）、表达矩阵（通过表达芯片、RNA-seq得到）
准备数据：测序数据（获取数据：A. 测序公司、B. 下载数据）、参考基因组（基因组序列genome.fasta、基因注释genes.gtf）、数据信息表samples.txt
转录组分析教程密码：dPDPs7IK27rmZGX
```
- 第一步：下载测序数据
```shell
# 安装软件
conda install sra-tools
# 安装完成后，使用prefetch命令下载测序数据
prefetch SRR2176381
# 批量生成下载数据
awk '{print "prefetch "$1}' SRR_Acc_List.txt > run_prefetch.sh
# 运行sh文件
sh run_prefetch.sh
# 下载完成后，我们得到的是sra格式的文件，需要将其转换为fastq格式才能使用
fastq-dump --split-3 SRR2176358.sra
# gz格式压缩文件不要解压，几乎所有软件都支持读取压缩文件
# 从网站上下载下来的基因组是分染色体的，将文件解压后合并为一个fasta文件
# 如果下载不到gtf而是gff可以使用下列命令转换
gffread -T -o genes.gtf HFTH1.gene.gff3
# 在比对前最好做一下测序数据的过滤和质控，这里先不讲
```
- 第二步：为参考序列构建Index
```shell
hisat2-build ../ref/genome.fasta ../ref/genome 1>hisat2-build.log 2>&1 # 作用：比对前需要先对参考基因组进行构建
# ../ref/genome.fasta是参考基因组的路径
# ../ref/genome是构建好的基因组叫什么名字
# 运行后生成8个文件，这8个文件当做黑匣子，不用管它的意义
# genome.1.ht2
# genome.2.ht2
# genome.3.ht2
# genome.4.ht2
# genome.5.ht2
# genome.6.ht2
# genome.7.ht2
# genome.8.ht2
```
- 第三步：将序列比对到参考基因组
```shell
hisat2 --new-summary -p 10 -x ../ref/genome -U ../data/BLO_S1_LD1.fq.gz -S BLO_S1_LD1.sam --rna-strandness R 1>BLO_S1_LD1.log 2>&1 #分别将每个样本的测试数据比对到参考基因组
# --new-summary 使用最新的模板生成报告
# -p 10 线程数，建议自己跑的时候设置为2个或4个
# -x 后面跟的构建好的参考基因组目录，只要前缀
# -U 如果是单末端测序就写-U后面加数据路径，双末端测序就写-1后面跟第一个文件，-2后跟第二个文件
# -S 后面是输出文件的路径
# --rna-strandness 普通文库不加，链特异性文库可当作普通文库处理，只是花的时间长一些，但普通文库不能当成链特异性文库处理
# 输入.ht2 输出.sam和.log
```
- 第四步：压缩和排序（把sam文件转换为bam文件）
```shell
samtools sort -o BLO_S1_LD1.bam BLO_S1_LD1.sam # sort排序 -o output 作用：sam压缩为bam并排序
# 输入.sam 输出.bam
```
- 第五步：bam index
```shell
samtools index BLO_S1_LD1.bam # 作用：生成bai文件供IGV使用
# 输入.bam 输出.bam.bai
```
- 第六步：表达定量
```shell
conda install r-base # 安装R
conda install bioconductor-rsubread # 安装rsubread
conda install bioconductor-edger # 安装edger
conda install bioconductor-limma # 安装limma
```

```r
# R语言脚本 run-featurecounts.R
#!/usr/bin/env Rscript
# parse parameter ---------------------------------------------------------
library(argparser, quietly=TRUE)
# Create a parser
p <- arg_parser("run featureCounts and calculate FPKM/TPM")

# Add command line arguments
p <- add_argument(p, "--bam", help="input: bam file", type="character")
p <- add_argument(p, "--gtf", help="input: gtf file", type="character")
p <- add_argument(p, "--output", help="output prefix", type="character")

# Parse the command line arguments
argv <- parse_args(p)

library(Rsubread)
library(limma)
library(edgeR)

bamFile <- argv$bam
gtfFile <- argv$gtf
nthreads <- 1
outFilePref <- argv$output

outStatsFilePath  <- paste(outFilePref, '.log',  sep = ''); 
outCountsFilePath <- paste(outFilePref, '.count', sep = ''); 

fCountsList = featureCounts(bamFile, annot.ext=gtfFile, isGTFAnnotationFile=TRUE, nthreads=nthreads, isPairedEnd=TRUE) # 注意若为单末端测序isPairedEnd=FALSE,大部分情况下是双末端测序，这次是单末端测序
dgeList = DGEList(counts=fCountsList$counts, genes=fCountsList$annotation)
fpkm = rpkm(dgeList, dgeList$genes$Length)
tpm = exp(log(fpkm) - log(sum(fpkm)) + log(1e6))

write.table(fCountsList$stat, outStatsFilePath, sep="\t", col.names=FALSE, row.names=FALSE, quote=FALSE)

featureCounts = cbind(fCountsList$annotation[,1], fCountsList$counts, fpkm, tpm)
colnames(featureCounts) = c('gene_id', 'counts', 'fpkm','tpm')
write.table(featureCounts, outCountsFilePath, sep="\t", col.names=TRUE, row.names=FALSE, quote=FALSE)

```
```shell
Rscript script/run-featurecounts.R -b ../1.Mapping/BLO_S1_LD1.bam -g ../ref/genes.gtf -o BLO_S1_LD1 
# Rscript运行R脚本 -b bam -g gtf -o output
# 输入.bam .gtf 输出.count .log
```

```shell
ls ../2.Quantification/*.count >genes.quant_files.txt

perl abundance_estimates_to_matrix.pl --est_method featureCounts --quant_files genes.quant_files.txt --out_prefix genes
```