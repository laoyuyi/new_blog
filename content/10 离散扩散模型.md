#### 离散扩散模型

https://zhuanlan.zhihu.com/p/636776166
https://zhuanlan.zhihu.com/p/650394311?utm_id=0
[系列文章](https://zhuanlan.zhihu.com/p/637815071)
[Arxiv](https://arxiv.org/abs/2006.11239)

---

##### DDPM

###### (1) 模型介绍
- 扩散模型是把数据从有序变无序，生成一系列的从有序到无序的样本，再去学习从无序变有序的过程：

![[assets/Pasted image 20241121175031.png|700]]

- $KL$散度又称交换熵，可以用来衡量两个分布的差异，DDPM的目标是使生成的图片尽可能地符合训练数据的分布，也就是使$KL(p_{data}||p_{\theta})$尽可能达到最小
$$
\begin{align}
KL(p||q)
&=\sum^{m}_{i=1}p(x_i) log \frac{p(x_i)}{q(x_i)}&(原始定义)\\\\
&=-\sum^{m}_{i=1}p(x_i) log \frac{q(x_i)}{p(x_i)}&(变形)\\\\
&=-\int_{x}p(x) log \frac{q(x)}{p(x)}x&(再变形)
\end{align}
$$
 - 对于两个高斯分布$p\sim \mathcal{N}(\mu _{1}, \sigma _{1}^{2})$和$q\sim \mathcal{N}(\mu _{2}, \sigma _{2}^{2})$，它们的$KL$散度$D_{KL}(p,q)$为：
$$D_{KL}(p,q) = \log \frac{\sigma _{2}}{\sigma _{1}} + \frac{\sigma _{1}^{2} + (\mu _{1} - \mu _{2})^{2}}{2 \sigma _{2}^{2}} - \frac{1}{2}$$
######  (2) 扩散过程

- 设$x_{t}$为第$t$步时的图片，$\beta_{t}$为噪声方差，$z_t$为高斯分布，定义扩散公式为以下$3$条公式：
$$
\begin{align}
&x_{t}=\sqrt{1-\beta _{t}}x_{t-1}+\sqrt{\beta _{t}}z _{t}&(z_{t}\sim N(0,\boldsymbol{I}))\\\\
&q(x_{t}|x_{t-1}) = N(x_{t}; \sqrt{1 - \beta _{t}}x_{t-1}, \beta_{t}\boldsymbol{I})&(概率分布形式)\\\\
&q(x_{1:T}|x_{0})=q(x_{1}|x_{0})×q(x_{2}|x_{1})×\cdots×q(x_{T}|x_{T-1})=\prod_{t=1}^{T}q(x_{t}|x_{t-1})&(联合概率分布)
\end{align}
$$
> [!note] 注释
> 简单来讲，扩散公式定义了这样一个东西，那就是在扩散加噪过程当中，任意一步的图像和它上一步的未加噪的图像之间是一个什么关系。
>其中，是一个超参数，又称扩散率，取值区间为$[0,1]$，数值随步数的增加而逐渐增大。
- 定义 $\alpha _{t} = 1 - \beta _{t}$，即 $\alpha _{t} + \beta _{t} = 1$ ，迭代推导可得：
$$
\begin{align}
x_{t} 
&= \sqrt{1-\beta _{t}}x_{t-1} + \sqrt{\beta _{t}}z _{t}\\\\
&= \sqrt{\alpha _{t}}x_{t-1}+\sqrt{\beta _{t}}z _{t} &(将\alpha _{t} = 1 - \beta _{t}代入)\\\\
&=\sqrt{\alpha _{t}}(\sqrt{\alpha _{t-1}}x_{t-2} + \sqrt{\beta _{t-1}}z _{t-1}) + \sqrt{\beta _{t}}z _{t} &(将x_{t-1}拆开)\\\\
&=\sqrt{\alpha _{t}\alpha _{t-1}}x_{t-2}+\sqrt{\alpha _{t}\beta _{t-1}}z _{t-1}+\sqrt{\beta _{t}}z _{t} &(展开)\\\\
&=\sqrt{\alpha _{t}\alpha _{t-1}}(\sqrt{\alpha _{t-2}}x_{t-3} + \sqrt{\beta _{t-2}}z _{t-2}) + \sqrt{\alpha _{t}\beta _{t-1}}z _{t-1} + \sqrt{\beta _{t}}z _{t}&(将x_{t-2}拆开)\\\\
&=\sqrt{\alpha _{t}\alpha _{t-1}\alpha _{t-2}}x_{t-3} + \sqrt{\alpha _{t}\alpha _{t-1}\beta _{t-2}}z _{t-2} + \sqrt{\alpha _{t}\beta _{t-1}}z _{t-1} + \sqrt{\beta _{t}}z _{t}&(展开)\\\\
&= \sqrt{\alpha _{t}\alpha _{t-1}\cdots \alpha _{1}}x_{0} + \sqrt{\alpha _{t}\alpha _{t-1}\cdots \alpha _{2}\beta _{1}}z _{1} + \sqrt{\alpha _{t}\alpha _{t-1}\cdots \alpha _{3}\beta _{2}}z _{2} + \\\\
&\cdots + \sqrt{\alpha _{t}\alpha _{t-1}\beta _{t-2}}z _{t-2} + \sqrt{\alpha _{t}\beta _{t-1}}z _{t-1} + \sqrt{\beta _{t}}z _{t} &(最终结果)
\end{align}
$$
- 设$\bar{\alpha }_{t}=\alpha _{t}\alpha _{t-1}\cdots \alpha _{1}$，则高斯噪声的方差之和为$1-\bar{\alpha }_{t}$，则刚开始的$3$条公式就变成了以下的样子：
$$
\begin{align}
&x_{t} = \sqrt{\bar{\alpha }_{t}}x_{0} + \sqrt{1-\bar{\alpha }_{t}}\bar{z}_{t}&\left(\bar{z}_t \sim N\left(0,\boldsymbol{I}\right)\right)\\\\
&q(x_{t}|x_{0}) = N(x_{t}; \sqrt{\bar{\alpha }_{t}}x_{0}, (1-\bar{\alpha }_t)\boldsymbol{I})&\left(概率分布形式\right)\\\\
&q(x_{1:T}|x_{0})=q(x_{1}|x_{0})×q(x_{2}|x_{1})×\cdots×q(x_{T}|x_{T-1})=\prod_{t=1}^{T}q(x_{t}|x_{t-1})&(联合概率分布)
\end{align}
$$
> [!NOTE] 结论
> 上面这一堆推导过程实际上是想说明：$x=[x_0,x_1,x_2,...,x_T]$中的任何一项都可以直接从$x_0$直接推导出来而不用一步一步去计算。只要给定初始值，以及每一步的扩散率，就可以得到任意时刻的$x_{t}$。当加噪步数$T$足够大时， $\bar{\alpha }_{t}$趋向于$0$，$1-\bar{\alpha }_{t}$趋向于$1$，所以$x_{T}$趋向于标准高斯分布。证明：高斯分布的相加或相乘仍然是高斯分布(证明过程略)。

###### (3) 去噪过程

> [!NOTE]-
>根据去噪过程，我们有以下公式：
>$$
>\begin{align}
>&p_{\theta}(x_{t-1}|x_{t})= \frac{q(x_{t-1})q(x_{t}|x_{t-1})}{q(x_{t})}=N\left(x_{t-1};\mu_{\theta}(x_{t},t),\Sigma _{\theta}(x_{t},t)\right)&(贝叶斯公式、概率分布形式)\\\\
>&p_{\theta}(x_{0:T}) = p_{\theta}(x_{T})×p_{\theta}(x_{T-1}|x_{T})×\cdots×p_{\theta}(x_{0}|x_{1}) = p_{\theta}(x_{T}) \prod_{t=1}^{T}p_{\theta}(x_{t-1}|x_{t})&(联合概率分布)
>\end{align}
>$$

- 在反向过程中，我们实际上是在已知已知$x_t$的条件下预测$x_{t-1}$，由于$x_{0}$也是已知的 ，则$q(x_{t-1}\mid x_{t}, x_{0})$为：

$$
q(x_{t-1}\mid x_{t}, x_{0}) = \frac{q(x_{t}\mid x_{t-1}, x_{0})\times q(x_{t-1}\mid x_{0})}{q(x_{t}\mid x_{0})} = N\left ( x_{t-1}; \tilde{\mu }(x_{t}, x_{0}), \tilde{\beta }_{t}\boldsymbol{I} \right)
$$

- 又根据前向过程的推导，我们有下面三个式子：

$$
\begin{align}
&q(x_{t-1}| x_{0}) = \sqrt{\bar{\alpha }_{t-1}}x_{0} + \sqrt{1-\bar{\alpha }_{t-1}}\bar{z}_{t-1}=N\left ( x_{t-1}; \sqrt{\bar{\alpha }_{t-1}}x_{0}, \left ( 1-\bar{\alpha }_{t-1} \right )\boldsymbol{I} \right )\\\\
&q(x_{t}\mid x_{0}) = \sqrt{\bar{\alpha }_{t}}x_{0} + \sqrt{1-\bar{\alpha }_{t}}\bar{z}_{t}=N\left(x_{t}; \sqrt{\bar{\alpha }_{t}}x_{0}, (1-\bar{\alpha }_{t})\boldsymbol{I} \right)\\\\
&q(x_{t}\mid x_{t-1}, x_{0}) = q(x_{t}\mid x_{t-1}) = \sqrt{\alpha _{t}}x_{t-1} + \sqrt{\beta _{t}}z _{t}=N\left ( x_{t}; \sqrt{\alpha _{t}}x_{t-1}, \beta _{t} \boldsymbol{I} \right)
\end{align}
$$

- 将前向传播过程推导得到的三个式子代入$q(x_{t-1}\mid x_{t}, x_{0})$得到：
$$
\begin{align}
q(x_{t-1}\mid x_{t}, x_{0}) 
&= \frac{N(x_{t}; \sqrt{\alpha _{t}}x_{t-1}, \beta _{t} \boldsymbol{I}) \times N(x_{t-1}; \sqrt{\bar{\alpha }_{t-1}}x_{0}, (1-\bar{\alpha }_{t-1})\boldsymbol{I})}{N(x_{t}; \sqrt{\bar{\alpha }_{t}}x_{0}, (1-\bar{\alpha }_{t})\boldsymbol{I})}\\\\
&\propto \exp \left[ -\frac{1}{2}\left ( \frac{(x_{t} - \sqrt{\alpha _{t}}x_{t-1})^{2}}{\beta _{t}} + \frac{(x_{t-1} - \sqrt{\bar{\alpha }_{t-1}}x_{0})^{2}}{1-\bar{\alpha }_{t-1}} - \frac{(x_{t} - \sqrt{\bar{\alpha }_{t}}x_{0})^{2}}{1 - \bar{\alpha }_{t}} \right ) \right]\\\\
&= \exp \left[ -\frac{1}{2}\left ( \frac{x_{t}^{2} - 2 \sqrt{\alpha _{t}}x_{t}x_{t-1} + \alpha_{t}x_{t-1}^{2}}{\beta _{t}} + \frac{ x_{t-1}^{2} - 2 \sqrt{\bar{\alpha }_{t-1}}x_{0}x_{t-1} + \bar{\alpha }_{t-1}x_{0}^{2}}{1-\bar{\alpha }_{t-1}} - \frac{(x_{t} - \sqrt{\bar{\alpha }_{t}}x_{0})^{2}}{1 - \bar{\alpha }_{t}} \right ) \right]\\\\
&=\exp \left[-\frac{1}{2}\left( \left( 
\frac{\alpha_{t}}{\beta_{t}} + \frac{1}{1 - \bar{\alpha}_{t-1}}
\right)x_{t-1}^{2} - \left( \frac{2\sqrt{\alpha_{t}}}{\beta_{t}} x_{t}+ \frac{2 \sqrt{\bar{\alpha}_{t-1}}}{1 - \bar{\alpha}_{t-1}}x_{0} \right)x_{t-1} + \mathcal{C}\left ( x_{t}, x_{0} \right) \right) \right]&(???)
\end{align}
$$
- 在上述推导得到的最终式子，我们可以将其对应：
$$
\exp \left[-\frac{1}{2}\left( 
\underbrace{\left(\frac{\alpha_{t}}{\beta_{t}} + \frac{1}{1 - \bar{\alpha}_{t-1}}\right)}_{\frac{1}{\tilde{\beta _{t}} ^{2}} }
x_{t-1}^{2} - 
\underbrace{\left( \frac{2\sqrt{\alpha_{t}}}{\beta_{t}} x_{t}+ \frac{2 \sqrt{\bar{\alpha}_{t-1}}}{1 - \bar{\alpha}_{t-1}}x_{0} \right)}_{\frac{2 \tilde{\mu }(x_{t}, x_{0}) }{\tilde{\beta _{t}} ^{2}}}
x_{t-1} + \mathcal{C}\left ( x_{t}, x_{0} \right) \right) \right]
$$

- 我们对上面对应的两个式子进行推导：

$$
\begin{align}
\frac{1}{\tilde{\beta _{t}} ^{2}} 
&= \frac{\alpha_{t}}{\beta_{t}} + \frac{1}{1 - \bar{\alpha}_{t-1}}&(公式1)\\\\
&= \frac{\alpha _{t}(1-\bar{\alpha }_{t-1}) + \beta _{t}}{\beta _{t}(1 - \bar{\alpha }_{t-1})}&(合并整理一下)\\\\
&= \frac{\alpha_{t}-\alpha_{t} \bar{\alpha }_{t-1} +  1 - \alpha _{t}}{\beta _{t}(1 - \bar{\alpha }_{t-1})} &(将\beta_t = 1-\alpha_t代入)\\\\
&= \frac{1 - \bar{\alpha }_{t}}{\beta _{t}(1 - \bar{\alpha }_{t-1})} &(消去)\\\\\\\\
\frac{2 \tilde{\mu }(x_{t}, x_{0}) }{\tilde{\beta _{t}} ^{2}}
&=\frac{2\sqrt{\alpha _{t}}}{\beta _{t}}x_{t} + \frac{2\sqrt{\bar{\alpha }_{t-1}}}{1 - \bar{\alpha }_{t-1}}x_{0}&(公式2)\\\\
\tilde{\mu }(x_{t}, x_{0})
&= \left ( \frac{\sqrt{\alpha _{t}}}{\beta _{t}}x_{t} + \frac{\sqrt{\bar{\alpha } _{t-1}}}{1-\bar{\alpha }_{t-1}}x_{0} \right )\times \tilde{\beta _{t} ^{2}}&(把\tilde{\mu }移到右边，两边除以2)\\\\
&= \left ( \frac{\sqrt{\alpha _{t}}}{\beta _{t}}x_{t} + \frac{\sqrt{\bar{\alpha } _{t-1}}}{1-\bar{\alpha }_{t-1}}x_{0} \right )\times \frac{1-\bar{\alpha }_{t-1}}{1-\bar{\alpha }_{t}}\beta _{t}&(把\tilde{\beta _{t}}展开)\\\\
&= \frac{\sqrt{\alpha _{t}}(1-\bar{\alpha }_{t-1})}{1 - \bar{\alpha }_{t}}x_{t} + \frac{\sqrt{\bar{\alpha }_{t-1}}}{1 - \bar{\alpha }_{t}}\beta _{t}x_{0}\\\\
&= \frac{\sqrt{\alpha _{t}}(1-\bar{\alpha }_{t-1})}{1 - \bar{\alpha }_{t}}x_{t} + \frac{\sqrt{\bar{\alpha }_{t-1}}}{1 - \bar{\alpha }_{t}}\beta _{t}\frac{x_{t} - \sqrt{1 - \bar{\alpha }_{t}}\bar{z}_{t} }{\sqrt{\bar{\alpha }_{t}}}\\\\
&= \left ( \frac{\sqrt{\alpha _{t}}(1 - \bar{\alpha }_{t-1})}{1 - \bar{\alpha }_{t}} + \frac{\beta _{t}\sqrt{\bar{\alpha }_{t-1}}}{\sqrt{\bar{\alpha } _{t}}(1 - \bar{\alpha }_{t})} \right )x_{t} - \frac{\sqrt{\bar{\alpha }_{t-1}}\sqrt{1 - \bar{\alpha }_{t}}\beta _{t}\bar{z}_{t} }{\sqrt{\bar{\alpha } _{t}}(1 - \bar{\alpha }_{t})}\\\\
&= \left ( \frac{\sqrt{\alpha _{t}}(1-\bar{\alpha }_{t-1})}{1 - \bar{\alpha }_{t}} + \frac{1 - \alpha _{t}}{\sqrt{\alpha _{t}}}(1 - \bar{\alpha }_{t}) \right )x_{t} - \frac{\beta _{t}\bar{z}_{t} }{\sqrt{\alpha _{t}}\sqrt{1 - \bar{\alpha }_{t}}}\\\\
&= \frac{\alpha _{t}(1 - \bar{\alpha }_{t-1}) + 1 - \alpha _{t}}{\sqrt{\alpha _{t}}(1 - \bar{\alpha }_{t})}x_{t} - \frac{\beta _{t}\bar{z}_{t} }{\sqrt{\alpha _{t}}\sqrt{1-\bar{\alpha }_{t}}}\\\\
&= \frac{1 - \alpha _{t}\bar{\alpha }_{t-1}}{\sqrt{\alpha _{t}}(1 - \bar{\alpha }_{t})}x_{t} - \frac{\beta _{t}\bar{z}_{t} }{\sqrt{\alpha _{t}}\sqrt{1-\bar{\alpha }_{t}}} &(???)\\\\
&= \frac{1 - \bar{\alpha }_{t}}{\sqrt{\alpha _{t}}(1 - \bar{\alpha }_{t})}x_{t} - \frac{\beta _{t}\bar{z}_{t} }{\sqrt{\alpha _{t}}\sqrt{1-\bar{\alpha }_{t}}}\\\\
&= \frac{1}{\sqrt{\alpha _{t}}}\left ( x_{t} - \frac{\beta _{t}}{\sqrt{1-\bar{\alpha }_{t}}}\bar{z}_{t}\right)\\\\\\\\
\therefore \quad q(x_{t-1}|x_t, x_{0})&= N\left(x_{t-1}, \tilde{\mu}(x_t,x_0),\tilde{\beta}_t^2\boldsymbol{I}\right)\\\\
&=N\left[x_{t-1},\frac{1}{\sqrt{\alpha_t}\left(x_t-\frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\bar{z}_t \right)},\frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t}\beta_t \boldsymbol{I} \right]
\end{align}
$$

> [!NOTE] 注释
> 所以在给定 $x_{0}$ 的条件下，反向过程真实的概率分布的均值只与 $x_{t}$ 和 $\bar{z}_{t}$ 有关

###### (4) 优化目标
<!--
\begin{align}
argmin_{\theta}\left[KL(P_{data}||P_{\theta})\right]
&=argmin_{\theta}\left[-\int_x P_{data}(x) log \frac{P_{\theta}(x)}{P_{data}(x)}dx\right]\\\\
&=argmax_{\theta}\left[\int_x P_{data}(x) log \frac{P_{\theta}(x)}{P_{data}(x)}dx\right]&\text{(删除负号，argmin变成argmax)}\\\\
&=argmax_{\theta}\left[\int_x P_{data}(x) log P_{\theta}(x)dx\right] -argmax_{\theta}\left[\int_{x}P_{data}(x) log P_{data}(x)dx\right]&(删除分号)\\\\
&=argmax_{\theta}\left[\int_x P_{data}(x) log P_{\theta}(x)dx\right]&(上式右半部分属于常数项，与模型无关，删除)\\\\
&=argmax_{\theta}\left[E_{x \sim P_{data}}(logP_{\theta}(x))\right]\\\\
&\approx argmax_{\theta}\left[\sum_{i=1}^{m} log P_{\theta}(x_i)\right]\\\\
&=argmax_{\theta} \left[ log \prod_{i=1}^{m}P_{\theta}(x_i)\right]\\\\
&=argmax_{\theta}\left[ \prod_{i=1}^{m}P_{\theta}(x_i)\right]
\end{align}
-->
- 我们模型的目标是对$P_{\theta}$做[极大似然估计](https://baike.baidu.com/item/%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/3350286?fr=ge_ala)，我们设$q(z|x)$为从原始分布到高斯分布的映射，则$P_{\theta}$的对数为：
$$
\begin{align}
log \left[P_{\theta}(x)\right]&=log\left[P_{\theta}(x)\right]×\int_x q(z|x)dz &(概率密度函数积分等于1，相当于借过来)\\\\
&=\int_x q(z|x)logP_{\theta}(x)dz\\\\
&=E_{q(z|x)}[logP_{\theta}(x)]dz\\\\
&=E_{q(z|x)}[log\frac{P_{\theta}(x,z)}{P_{\theta}(z|x)}]\\\\
&=E_{q(z|x)}[log\frac{P_{\theta}(x,z)q(z|x)}{P_{\theta}(z|x)q(z|x)}]\\\\
&=E_{q(z|x)}[log\frac{P_{\theta}(x,z)}{q(z|x)}]+E_{(z|x)}[log\frac{q(z|x)}{P_{\theta}(z|x)}]\\\\
&=E_{q(z|x)}[log\frac{P_{\theta}(x,z)}{q(z|x)}]+KL(q(z|x)||P_{\theta}(z|x))\\\\
&\geq E_{q(z|x)}[log \frac{P_{\theta}(x,z)}{q(z|x)}]&(KL散度一定大于0)
\end{align}
$$

- 我们要最大化$log(P_{\theta}(x))$，相当于最小化$-log(P_{\theta}(x))$，我们定义变量下界为$L_{VLB}$，由于从原始分布到高斯分布的映射也就是前向传播过程，所以我们可以把前向传播的公式套过来，替换公式中的$q(z|x)$，得到：

$$
log\left[P_{\theta}(x)\right]\geq E_{q(x_{1:T}|x_0)}\left[log(\frac{p_{\theta}(x_{0:T})}{q(x_{1:T}|x_0)})\right]
$$

- 我们设$L_{VLB}$为变分下界，并对$L_{VLB}$进行推导，即：
$$
\begin{align}
L_{VLB}
&=E_{q(x_{1:T}|x_0)}\left[log(\frac{p_{\theta}(x_{0:T})}{q(x_{1:T}|x_0)})\right]\\\\
&= \mathbb{E}_{ q(x_{1:T}|x_{0})}\left [\log \frac{ q(x_{1:T}|x_{0})}{p_{\theta}(x_{0:T})}\right]
&(取负对数，相当于把log上下交换)\\\\
&= \mathbb{E}_{ q(x_{1:T}|x_{0})}\left [\log \frac{\prod_{t=1}^{T} q(x_{t}|x_{t-1})}{p_{\theta}(x_{T}) \prod_{t=1}^{T} p_{\theta}(x_{t-1}|x_{t})}\right]
&(把前面推导的内容代入式子)\\\\
&= \mathbb{E}_{ q(x_{1:T}|x_{0})}\left [-\log p_{\theta}(x_{T}) + \sum_{t=1}^{T}\log \frac{q(x_{t}|x_{t-1})}{p_{\theta}(x_{t-1}|x_{t})}\right]
&log(AB)=log(A)+log(B)\\\\
&= \mathbb{E}_{ q(x_{1:T}|x_{0})}\left [-\log p_{\theta}(x_{T}) + \sum_{t=2}^{T}\log \frac{q(x_{t}|x_{t-1})}{p_{\theta}(x_{t-1}|x_{t})} + \log \frac{q(x_{1}|x_{0})}{p_{\theta }(x_{0}|x_{1})}\right]
&(把t=1拆出来)\\\\
&= \mathbb{E}_{ q(x_{1:T}|x_{0})}\left [-\log p_{\theta}(x_{T}) + \sum_{t=2}^{T}\log \frac{q(x_{t}|x_{t-1}, x_{0})}{p_{\theta}(x_{t-1}|x_{t})} + \log \frac{q(x_{1}|x_{0})}{p_{\theta }(x_{0}|x_{1})}\right]
&q(x_{t}|x_{t-1}, x_{0})=q(x_{t}|x_{t-1})\\\\
&= \mathbb{E}_{ q(x_{1:T}|x_{0})}\left [-\log p_{\theta}(x_{T}) + \sum_{t=2}^{T}\log \left(\frac{q(x_{t-1}|x_{t},x_{0})}{p_{\theta}(x_{t-1}|x_{t})}\cdot \frac{q(x_{t}|x_{0})}{q(x_{t-1}|x_{0})}\right) + \log \frac{q(x_{1}|x_{0})}{p_{\theta }(x_{0}|x_{1})}\right]
&(借过来)\\\\
&= \mathbb{E}_{ q(x_{1:T}|x_{0})}\left [-\log p_{\theta}(x_{T}) + \sum_{t=2}^{T}\log \frac{q(x_{t-1}|x_{t}, x_{0})}{p_{\theta}(x_{t-1}|x_{t})} + \sum_{t=2}^{T}\log \frac{q(x_{t}|x_{0})}{q(x_{t-1}|x_{0})} + \log \frac{q(x_{1}|x_{0})}{p_{\theta }(x_{0}|x_{1})}\right]
&(再拆开)\\\\
&= \mathbb{E}_{ q(x_{1:T}|x_{0})}\left [-\log p_{\theta}(x_{T}) + \sum_{t=2}^{T}\log \frac{q(x_{t-1}|x_{t}, x_{0})}{p_{\theta}(x_{t-1}|x_{t})} + \log \frac{q(x_{T}|x_{0})}{q(x_{1}|x_{0})} + \log \frac{q(x_{1}|x_{0})}{p_{\theta }(x_{0}|x_{1})}\right]&\sum_{t=2}^{T}\log \frac{q(x_{t}|x_{0})}{q(x_{t-1}|x_{0})}=\log \frac{q(x_{T}|x_{0})}{q(x_{1}|x_{0})}\\\\
&= \mathbb{E}_{ q(x_{1:T}|x_{0})}\left [\log \frac{q(x_{T}|x_{0})}{p_{\theta}(x_{T})} + \sum_{t=2}^{T}\log \frac{q(x_{t-1}|x_{t}, x_{0})}{p_{\theta}(x_{t-1}|x_{t})} - \log p_{\theta}(x_{0}|x_{1})\right]
&(把最后一项去掉，整理一下)
\end{align}
$$

---

###### PPT
![[assets/Pasted image 20241124184955.png]]
![[assets/Pasted image 20241124184632.png]]
![[assets/Pasted image 20241124193739.png]]
![[assets/Pasted image 20241124203846.png]]
![[assets/Pasted image 20241124204025.png]]
![[assets/Pasted image 20241124204040.png]]
![[assets/Pasted image 20241124213123.png]]
![[assets/Pasted image 20241124221845.png]]